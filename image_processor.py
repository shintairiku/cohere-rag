"""
ç”»åƒå‡¦ç†å°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
"""

import os
import base64
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Set
from dotenv import load_dotenv
import cohere
import numpy as np

load_dotenv()

class ImageProcessor:
    def __init__(self, images_dir: str = "images", embeddings_file: str = "embeddings.json"):
        self.images_dir = Path(images_dir)
        self.embeddings_file = embeddings_file
        self.api_key = os.getenv("COHERE_API_KEY")
        
        if not self.api_key:
            raise ValueError("COHERE_API_KEY not found in environment variables")
        
        self.client = cohere.ClientV2(api_key=self.api_key)
        self.processed_images: Set[str] = set()
        self.embeddings_data: List[Dict] = []
        
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        self.load_existing_data()
    
    def load_existing_data(self):
        """æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.embeddings_file):
            try:
                with open(self.embeddings_file, 'r', encoding='utf-8') as f:
                    self.embeddings_data = json.load(f)
                
                # å‡¦ç†æ¸ˆã¿ç”»åƒã®ãƒãƒƒã‚·ãƒ¥ã‚’è¨˜éŒ²
                for item in self.embeddings_data:
                    if 'file_hash' in item:
                        self.processed_images.add(item['file_hash'])
                
                print(f"ğŸ“ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(self.embeddings_data)}ä»¶")
                print(f"ğŸ“ å‡¦ç†æ¸ˆã¿ç”»åƒ: {len(self.processed_images)}ä»¶")
            except Exception as e:
                print(f"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                self.embeddings_data = []
        else:
            print("ğŸ“‚ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™")
    
    def get_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰"""
        hash_sha256 = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_sha256.update(chunk)
        return hash_sha256.hexdigest()
    
    def image_to_base64_data_url(self, image_path: Path) -> str:
        """ç”»åƒã‚’base64ãƒ‡ãƒ¼ã‚¿URLã«å¤‰æ›"""
        with open(image_path, "rb") as image_file:
            base64_bytes = base64.b64encode(image_file.read())
            base64_string = base64_bytes.decode('utf-8')
            
            ext = image_path.suffix.lower()
            mime_type = {
                '.jpg': 'image/jpeg',
                '.jpeg': 'image/jpeg', 
                '.png': 'image/png',
                '.webp': 'image/webp',
                '.gif': 'image/gif'
            }.get(ext, 'image/jpeg')
            
            return f"data:{mime_type};base64,{base64_string}"
    
    def get_image_embedding(self, image_path: Path) -> np.ndarray:
        """ç”»åƒã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        try:
            base64_url = self.image_to_base64_data_url(image_path)
            
            image_input = {
                "content": [
                    {"type": "image_url", "image_url": {"url": base64_url}}
                ]
            }
            
            response = self.client.embed(
                model="embed-v4.0",
                inputs=[image_input],
                input_type="search_document",
                embedding_types=["float"]
            )
            
            embedding = response.embeddings.float_[0]
            return np.array(embedding)
            
        except Exception as e:
            print(f"âŒ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({image_path.name}): {e}")
            return None
    
    def process_new_images(self):
        """æ–°ã—ã„ç”»åƒã®ã¿ã‚’å‡¦ç†"""
        if not self.images_dir.exists():
            raise FileNotFoundError(f"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.images_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.gif'}
        image_files = [f for f in self.images_dir.iterdir() 
                      if f.suffix.lower() in image_extensions]
        
        new_images = []
        skipped_images = []
        
        # æ–°ã—ã„ç”»åƒã¨æ—¢å‡¦ç†ç”»åƒã‚’åˆ†é¡
        for image_path in image_files:
            file_hash = self.get_file_hash(image_path)
            if file_hash not in self.processed_images:
                new_images.append((image_path, file_hash))
            else:
                skipped_images.append(image_path.name)
        
        print(f"ğŸ“Š ç”»åƒåˆ†æçµæœ:")
        print(f"  ğŸ†• æ–°è¦ç”»åƒ: {len(new_images)}ä»¶")
        print(f"  â­ï¸  ã‚¹ã‚­ãƒƒãƒ—: {len(skipped_images)}ä»¶")
        
        if skipped_images:
            print(f"  ğŸ“‚ ã‚¹ã‚­ãƒƒãƒ—ã•ã‚ŒãŸç”»åƒ: {', '.join(skipped_images)}")
        
        if not new_images:
            print("âœ… å‡¦ç†ã™ã‚‹æ–°ã—ã„ç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“")
            return
        
        # æ–°ã—ã„ç”»åƒã‚’å‡¦ç†
        processed_count = 0
        for i, (image_path, file_hash) in enumerate(new_images, 1):
            print(f"ğŸ”„ å‡¦ç†ä¸­ {i}/{len(new_images)}: {image_path.name}")
            
            embedding = self.get_image_embedding(image_path)
            if embedding is not None:
                # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                new_data = {
                    "filename": image_path.name,
                    "filepath": str(image_path),
                    "file_hash": file_hash,
                    "file_size": image_path.stat().st_size,
                    "embedding": embedding.tolist()
                }
                
                self.embeddings_data.append(new_data)
                self.processed_images.add(file_hash)
                processed_count += 1
                
                print(f"âœ… å®Œäº†: {image_path.name}")
            else:
                print(f"âŒ å¤±æ•—: {image_path.name}")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä¿å­˜
        if processed_count > 0:
            self.save_embeddings()
            print(f"\nğŸ‰ å‡¦ç†å®Œäº†! æ–°ãŸã«{processed_count}ä»¶ã®ç”»åƒã‚’è¿½åŠ ã—ã¾ã—ãŸ")
            print(f"ğŸ“Š ç·ç”»åƒæ•°: {len(self.embeddings_data)}ä»¶")
        
    def save_embeddings(self):
        """åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(self.embeddings_file, 'w', encoding='utf-8') as f:
                json.dump(self.embeddings_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº†: {self.embeddings_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
    
    def show_status(self):
        """ç¾åœ¨ã®çŠ¶æ³ã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:")
        print(f"  ğŸ“ ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.images_dir}")
        print(f"  ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {self.embeddings_file}")
        print(f"  ğŸ“ˆ å‡¦ç†æ¸ˆã¿ç”»åƒæ•°: {len(self.embeddings_data)}ä»¶")
        
        if self.embeddings_data:
            print(f"\nğŸ“‚ å‡¦ç†æ¸ˆã¿ç”»åƒä¸€è¦§:")
            for item in self.embeddings_data:
                file_size_mb = item.get('file_size', 0) / (1024 * 1024)
                print(f"  - {item['filename']} ({file_size_mb:.2f}MB)")

def main():
    print("ğŸ–¼ï¸  ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ  - RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")
    print("=" * 50)
    
    processor = ImageProcessor()
    
    # ç¾åœ¨ã®çŠ¶æ³è¡¨ç¤º
    processor.show_status()
    
    # æ–°ã—ã„ç”»åƒã‚’å‡¦ç†
    print(f"\nğŸ”„ æ–°ã—ã„ç”»åƒã®å‡¦ç†ã‚’é–‹å§‹...")
    processor.process_new_images()
    
    print(f"\nâœ… ç”»åƒå‡¦ç†å®Œäº†!")
    print(f"æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹ã«ã¯: python search.py")

if __name__ == "__main__":
    main()