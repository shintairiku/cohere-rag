"""
ç”»åƒå‡¦ç†å°‚ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ - RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰
ï¼ˆå…±æœ‰ãƒ‰ãƒ©ã‚¤ãƒ–ã®è‡ªå‹•ç›£è¦–æ©Ÿèƒ½ä»˜ãï¼‰
"""

import os
import base64
import json
import hashlib
from pathlib import Path
from typing import List, Dict, Set
from dotenv import load_dotenv
import cohere
import numpy as np
import sys
import time
import argparse
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler

load_dotenv()

class ImageProcessor:
    def __init__(self, images_dir: str = "images", embeddings_file: str = "embeddings.json"):
        self.images_dir = Path(images_dir)
        self.embeddings_file = embeddings_file
        self.api_key = os.getenv("COHERE_API_KEY")
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.webp', '.gif'}

        if not self.api_key:
            raise ValueError("COHERE_API_KEY not found in environment variables")

        self.client = cohere.ClientV2(api_key=self.api_key)
        self.processed_images: Set[str] = set()
        self.embeddings_data: List[Dict] = []

        self.load_existing_data()

    def load_existing_data(self):
        """æ—¢å­˜ã®åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        if os.path.exists(self.embeddings_file):
            try:
                with open(self.embeddings_file, 'r', encoding='utf-8') as f:
                    self.embeddings_data = json.load(f)
                for item in self.embeddings_data:
                    if 'file_hash' in item:
                        self.processed_images.add(item['file_hash'])
                print(f"ğŸ“ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿: {len(self.embeddings_data)}ä»¶")
            except Exception as e:
                print(f"âŒ æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            print("ğŸ“‚ æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆã—ã¾ã™")

    def show_status(self):
        """ç¾åœ¨ã®çŠ¶æ³ã‚’è¡¨ç¤º"""
        print(f"\nğŸ“Š ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³:")
        print(f"  ğŸ“‚ å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.images_dir}")
        print(f"  ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«: {self.embeddings_file}")
        print(f"  ğŸ“ˆ å‡¦ç†æ¸ˆã¿ç”»åƒæ•°: {len(self.embeddings_data)}ä»¶")

        if self.embeddings_data:
            print(f"\nğŸ“„ å‡¦ç†æ¸ˆã¿ç”»åƒä¸€è¦§ (ä¸€éƒ¨):")
            for i, item in enumerate(self.embeddings_data[:5]):
                file_size_mb = item.get('file_size', 0) / (1024 * 1024)
                print(f"  - {item['filename']} ({file_size_mb:.2f}MB)")
            if len(self.embeddings_data) > 5:
                print(f"  ...ä»–{len(self.embeddings_data) - 5}ä»¶")

    def get_file_hash(self, file_path: Path) -> str:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒã‚·ãƒ¥å€¤ã‚’è¨ˆç®—ï¼ˆé‡è¤‡æ¤œå‡ºç”¨ï¼‰"""
        hash_sha256 = hashlib.sha256()
        try:
            with open(file_path, "rb") as f:
                for chunk in iter(lambda: f.read(4096), b""):
                    hash_sha256.update(chunk)
            return hash_sha256.hexdigest()
        except IOError as e:
            print(f"    âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ï¼ˆãƒãƒƒã‚·ãƒ¥è¨ˆç®—ä¸­ï¼‰: {file_path.name} - {e}")
            return None


    def image_to_base64_data_url(self, image_path: Path) -> str:
        """ç”»åƒã‚’base64ãƒ‡ãƒ¼ã‚¿URLã«å¤‰æ›"""
        with open(image_path, "rb") as image_file:
            base64_bytes = base64.b64encode(image_file.read())
            base64_string = base64_bytes.decode('utf-8')
            ext = image_path.suffix.lower()
            mime_type = {
                '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg', '.png': 'image/png',
                '.webp': 'image/webp', '.gif': 'image/gif'
            }.get(ext, 'image/jpeg')
            return f"data:{mime_type};base64,{base64_string}"

    def get_image_embedding(self, image_path: Path) -> np.ndarray:
        """ç”»åƒã®åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆ"""
        try:
            base64_url = self.image_to_base64_data_url(image_path)
            image_input = {"content": [{"type": "image_url", "image_url": {"url": base64_url}}]}
            response = self.client.embed(
                model="embed-v4.0", inputs=[image_input],
                input_type="search_document", embedding_types=["float"]
            )
            return np.array(response.embeddings.float_[0])
        except Exception as e:
            print(f"âŒ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã‚¨ãƒ©ãƒ¼ ({image_path.name}): {e}")
            return None

    def process_new_images(self):
        """æ–°ã—ã„ç”»åƒã®ã¿ã‚’ä¸€æ‹¬ã§å‡¦ç†"""
        if not self.images_dir.exists():
            raise FileNotFoundError(f"ç”»åƒãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª '{self.images_dir}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‘ã‚¹ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        
        print("\nâ³ å¯¾è±¡ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã—ã¦ã„ã¾ã™...")
        all_files = []
        scanned_dirs = 0
        try:
            for root, _, files in os.walk(self.images_dir):
                scanned_dirs += 1
                sys.stdout.write(f"\r  - ã‚¹ã‚­ãƒ£ãƒ³ä¸­: {scanned_dirs}å€‹ã®ãƒ•ã‚©ãƒ«ãƒ€ã‚’èª¿æŸ»æ¸ˆ...  ç¾åœ¨ã®å ´æ‰€: {root}")
                sys.stdout.flush()
                for filename in files:
                    if filename.lower().endswith(tuple(self.image_extensions)):
                        all_files.append(Path(root) / filename)
        except Exception as e:
            print(f"\nâŒ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚¹ã‚­ãƒ£ãƒ³ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return
        
        print(f"\n  â–¶ï¸  ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†ã€‚{len(all_files)}ä»¶ã®ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨ç…§åˆã—ã¾ã™...")

        new_images = []
        for image_path in all_files:
            file_hash = self.get_file_hash(image_path)
            if file_hash and file_hash not in self.processed_images:
                new_images.append((image_path, file_hash))
        
        print(f"  â–¶ï¸  ç…§åˆå®Œäº†ã€‚æ–°è¦ç”»åƒ: {len(new_images)}ä»¶")

        if not new_images:
            print("\nâœ… å‡¦ç†ã™ã‚‹æ–°ã—ã„ç”»åƒã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            return
        
        print(f"\nğŸ”„ æ–°ã—ã„ç”»åƒã®å‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™...")
        processed_count = 0
        for i, (image_path, file_hash) in enumerate(new_images, 1):
            print(f"  - å‡¦ç†ä¸­ {i}/{len(new_images)}: {image_path.name}")
            # process_single_imageãƒ¡ã‚½ãƒƒãƒ‰ã‚’å†åˆ©ç”¨
            if self.process_single_image(image_path, precomputed_hash=file_hash):
                 processed_count += 1

        if processed_count > 0:
            print(f"\nğŸ‰ ä¸€æ‹¬å‡¦ç†å®Œäº†! æ–°ãŸã«{processed_count}ä»¶ã®ç”»åƒã‚’è¿½åŠ ã—ã¾ã—ãŸ")
            print(f"ğŸ“Š ç·ç”»åƒæ•°: {len(self.embeddings_data)}ä»¶")


    def process_single_image(self, image_path: Path, precomputed_hash: str = None) -> bool:
        """ã€æ–°è¦è¿½åŠ ã€‘æŒ‡å®šã•ã‚ŒãŸå˜ä¸€ã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹"""
        if not image_path.exists() or image_path.suffix.lower() not in self.image_extensions:
            return False

        print(f"  - ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯: {image_path.name}")
        file_hash = precomputed_hash or self.get_file_hash(image_path)
        if not file_hash:
            return False

        if file_hash in self.processed_images:
            print(f"    â­ï¸  å‡¦ç†æ¸ˆã¿ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
            return False

        print(f"    ğŸ”„ åŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­...")
        embedding = self.get_image_embedding(image_path)
        if embedding is not None:
            new_data = {
                "filename": image_path.name,
                "filepath": str(image_path),
                "file_hash": file_hash,
                "file_size": image_path.stat().st_size,
                "embedding": embedding.tolist()
            }
            self.embeddings_data.append(new_data)
            self.processed_images.add(file_hash)
            self.save_embeddings()
            print(f"    âœ… å®Œäº†: {image_path.name}")
            return True
        else:
            print(f"    âŒ å¤±æ•—: {image_path.name}")
            return False

    def save_embeddings(self):
        """åŸ‹ã‚è¾¼ã¿ãƒ‡ãƒ¼ã‚¿ã‚’JSONãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        try:
            with open(self.embeddings_file, 'w', encoding='utf-8') as f:
                json.dump(self.embeddings_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜å®Œäº† (ç·æ•°: {len(self.embeddings_data)}ä»¶)")
        except Exception as e:
            print(f"âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

class ImageChangeHandler(FileSystemEventHandler):
    def __init__(self, processor: ImageProcessor):
        self.processor = processor

    def on_created(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚ŒãŸã¨ãã«å‘¼ã°ã‚Œã‚‹"""
        if not event.is_directory:
            print(f"\nğŸ†• æ–°è¦ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {event.src_path}")
            self.processor.process_single_image(Path(event.src_path))
    
    def on_moved(self, event):
        """ãƒ•ã‚¡ã‚¤ãƒ«ãŒç§»å‹•/åå‰å¤‰æ›´ã•ã‚ŒãŸã¨ãã«å‘¼ã°ã‚Œã‚‹"""
        if not event.is_directory:
            print(f"\nğŸ†• ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•/åå‰å¤‰æ›´æ¤œå‡º: {event.dest_path}")
            self.processor.process_single_image(Path(event.dest_path))


def run_batch_mode(processor: ImageProcessor):
    """ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹"""
    print("ğŸš€ ãƒãƒƒãƒãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™...")
    processor.show_status()
    processor.process_new_images()
    print(f"\nâœ… å…¨ã¦ã®å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸ!")
    print(f"â–¶ï¸  æ¤œç´¢ã‚’é–‹å§‹ã™ã‚‹ã«ã¯: python interactive_search.py")

def start_watching(processor: ImageProcessor, watch_path: str):
    """ç›£è¦–ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã™ã‚‹"""
    path = Path(watch_path)
    if not path.exists():
         print(f"âŒ ç›£è¦–å¯¾è±¡ã®ãƒ•ã‚©ãƒ«ãƒ€ '{watch_path}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
         sys.exit(1)

    print(f"ğŸ‘€ ç›£è¦–ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™ã€‚å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€: '{watch_path}'")
    
    # èµ·å‹•æ™‚ã«ã¾ãšä¸€æ‹¬å‡¦ç†ã‚’å®Ÿè¡Œã—ã€æœªå‡¦ç†ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã™ã‚‹
    print("\nğŸ” èµ·å‹•æ™‚ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ã—ã¾ã™...")
    processor.process_new_images()

    print("\nâœ… èµ·å‹•æ™‚ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†ã€‚ãƒ•ã‚©ãƒ«ãƒ€ã®ç›£è¦–ã‚’é–‹å§‹ã—ã¾ã™...ï¼ˆCtrl+Cã§çµ‚äº†ï¼‰")
    event_handler = ImageChangeHandler(processor)
    observer = Observer()
    observer.schedule(event_handler, watch_path, recursive=True)
    observer.start()
    try:
        while True:
            time.sleep(5)
    except KeyboardInterrupt:
        observer.stop()
        print("\nâ¹ï¸  ç›£è¦–ã‚’åœæ­¢ã—ã¾ã™ã€‚")
    observer.join()
    print("\nâœ… ç›£è¦–ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")


def main():
    """ãƒ¡ã‚¤ãƒ³ã®å®Ÿè¡Œé–¢æ•°ï¼ˆãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒãƒ£ãƒ¼ï¼‰"""
    print("ğŸ–¼ï¸  ç”»åƒå‡¦ç†ã‚·ã‚¹ãƒ†ãƒ  - RAGãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ§‹ç¯‰")
    print("=" * 50)
    
    parser = argparse.ArgumentParser(description="ç”»åƒå‡¦ç†ãŠã‚ˆã³ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ")
    parser.add_argument(
        '--mode', 
        type=str, 
        default='batch', 
        choices=['batch', 'watch'],
        help="å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ: 'batch' (ä¸€æ‹¬å‡¦ç†) or 'watch' (ãƒ•ã‚©ãƒ«ãƒ€ã‚’ç›£è¦–)"
    )
    args = parser.parse_args()

    image_source_path = os.getenv("IMAGE_SOURCE_PATH", "images")
    processor = ImageProcessor(images_dir=image_source_path)
    
    # ãƒ¢ãƒ¼ãƒ‰ã«å¿œã˜ã¦é©åˆ‡ãªé–¢æ•°ã‚’å‘¼ã³å‡ºã™
    if args.mode == 'batch':
        run_batch_mode(processor)
    elif args.mode == 'watch':
        start_watching(processor, image_source_path)


if __name__ == "__main__":
    main()