import os
import io
import re
import base64
import json
import hashlib
import traceback
from typing import Dict

import cohere
import numpy as np
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Request
from PIL import Image
from google.cloud import storage

import google.auth
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload

load_dotenv()

# --- è¨­å®š ---
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
GCS_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
MAX_FILE_SIZE = 20 * 1024 * 1024  # 20MB

if not all([GCS_BUCKET_NAME, COHERE_API_KEY]):
    raise RuntimeError("GCS_BUCKET_NAME and COHERE_API_KEY must be set.")

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ---
app = FastAPI()
co_client = cohere.Client(COHERE_API_KEY)
storage_client = storage.Client()

# --- èªè¨¼ãƒ˜ãƒ«ãƒ‘ãƒ¼ ---
def _get_google_credentials():
    creds, _ = google.auth.default(scopes=SCOPES)
    return creds

# --- ç”»åƒå‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ (img_meta_processor_gdrive.pyã‹ã‚‰ç§»æ¤ãƒ»æ”¹å¤‰) ---

def get_weighted_embedding(image_data: bytes, filename: str) -> np.ndarray:
    def get_embedding(text: str, input_type: str) -> np.ndarray:
        response = co_client.embed(texts=[text], model="embed-multilingual-v3.0", input_type=input_type)
        return np.array(response.embeddings[0])

    img_vec = get_embedding(filename, "search_document")
    meta_vec = get_embedding(filename, "search_query")
    
    w = np.dot(img_vec, meta_vec) / (np.linalg.norm(img_vec) * np.linalg.norm(meta_vec))
    vec = w * meta_vec + (1.0 - w) * img_vec
    return vec

def resize_image_if_needed(image_content: bytes, filename: str) -> bytes:
    if len(image_content) <= MAX_FILE_SIZE:
        return image_content
    # ... (ãƒªã‚µã‚¤ã‚ºå‡¦ç†ã¯ä»¥å‰ã®ã‚³ãƒ¼ãƒ‰ã¨åŒã˜) ...
    print(f"ğŸ“ Resizing large file: {filename}")
    try:
        img = Image.open(io.BytesIO(image_content))
        if img.mode in ('RGBA', 'LA', 'P'):
            background = Image.new('RGB', img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[-1])
            img = background
        
        for scale in [0.9, 0.8, 0.7, 0.6, 0.5]:
            for quality in [90, 80, 70, 60, 50]:
                new_size = (int(img.width * scale), int(img.height * scale))
                resized_img = img.resize(new_size, Image.Resampling.LANCZOS)
                output = io.BytesIO()
                resized_img.save(output, format='JPEG', quality=quality)
                resized_data = output.getvalue()
                if len(resized_data) <= MAX_FILE_SIZE:
                    return resized_data
    except Exception as e:
        print(f"âŒ Resize error for {filename}: {e}")
    return None # Return None if resizing fails or is still too large

# --- Pub/Subãƒˆãƒªã‚¬ãƒ¼ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---

@app.post("/process")
async def process_image_task(request: Request):
    """
    Pub/Subã‹ã‚‰ã®ãƒ—ãƒƒã‚·ãƒ¥ã‚µãƒ–ã‚¹ã‚¯ãƒªãƒ—ã‚·ãƒ§ãƒ³ã«ã‚ˆã£ã¦ãƒˆãƒªã‚¬ãƒ¼ã•ã‚Œã‚‹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚
    ç”»åƒ1æšã‚’å‡¦ç†ã—ã€çµæœã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦GCSã«ä¿å­˜ã™ã‚‹ã€‚
    """
    envelope = await request.json()
    if not envelope or 'message' not in envelope:
        raise HTTPException(status_code=400, detail="Invalid Pub/Sub message format")

    message = envelope['message']
    try:
        # Pub/Subãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ãƒ‡ã‚³ãƒ¼ãƒ‰
        payload_str = base64.b64decode(message['data']).decode('utf-8')
        payload = json.loads(payload_str)
        
        uuid = payload['uuid']
        file_id = payload['file_id']
        file_name = payload['file_name']
        web_view_link = payload['web_view_link']
        folder_path = payload['folder_path']
        
        print(f"ğŸ‘·â€â™€ï¸ Worker received task: Process {file_name} for UUID {uuid}")

        # Google Driveã‹ã‚‰ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        creds = _get_google_credentials()
        drive_service = build('drive', 'v3', credentials=creds)
        
        drive_request = drive_service.files().get_media(fileId=file_id)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, drive_request)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        image_content = fh.getvalue()
        
        # ç”»åƒã‚’ãƒªã‚µã‚¤ã‚º
        resized_content = resize_image_if_needed(image_content, file_name)
        if not resized_content:
            print(f"âš ï¸ Skipping {file_name} due to resize failure.")
            return {"status": "skipped", "reason": "resize_failed"}

        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–
        embedding = get_weighted_embedding(resized_content, file_name)
        
        # çµæœã‚’JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦æ§‹ç¯‰
        result_data = {
            "filename": file_name,
            "filepath": web_view_link,
            "folder_path": folder_path,
            "full_path": f"{folder_path}/{file_name}" if folder_path else file_name,
            "file_id": file_id,
            "file_hash": hashlib.sha256(resized_content).hexdigest(),
            "file_size": len(resized_content),
            "embedding": embedding.tolist()
        }

        # GCSã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
        bucket = storage_client.bucket(GCS_BUCKET_NAME)
        # ãƒ•ã‚¡ã‚¤ãƒ«IDã‚’ãƒ•ã‚¡ã‚¤ãƒ«åã«ä½¿ã„ã€é‡è¤‡ã‚’é˜²ã
        blob_path = f"temp/{uuid}/{file_id}.json"
        blob = bucket.blob(blob_path)
        blob.upload_from_string(json.dumps(result_data, ensure_ascii=False), content_type="application/json")

        print(f"âœ… Successfully processed and saved to {blob_path}")
        return {"status": "success"}

    except Exception as e:
        print(f"âŒ Worker error: {e}")
        traceback.print_exc()
        # Pub/Subã«å†è©¦è¡Œã•ã›ã‚‹ãŸã‚ã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/")
def health_check():
    return {"status": "ok", "service": "worker"}
