"""
Image Search and Vectorization API

This FastAPI application provides endpoints for:
1. Triggering vectorization jobs for Google Drive images
2. Searching similar images using Cohere embeddings
"""

import os
import traceback
from typing import Dict, Optional, List

import cohere
import gspread
from google.oauth2 import service_account
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Query
from pydantic import BaseModel
from google.cloud import run_v2

from search import ImageSearcher

load_dotenv()


class Config:
    """Configuration management for the application."""
    
    def __init__(self):
        self.gcs_bucket_name = os.getenv("GCS_BUCKET_NAME")
        self.gcp_project_id = os.getenv("GCP_PROJECT_ID")
        self.cohere_api_key = os.getenv("COHERE_API_KEY")
        self.vectorize_job_name = os.getenv("VECTORIZE_JOB_NAME", "cohere-rag-vectorize-job")
        self.gcp_region = os.getenv("GCP_REGION", "asia-northeast1")
        # Google Sheets ID ã¯ç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½ã€‚æœªæŒ‡å®šæ™‚ã¯ ENVIRONMENT ã«å¿œã˜ã¦æ—¢å®šå€¤ã‚’é¸ã¶
        dev_sheets_id = "1xPY1w4q9wm607hNK9Eb0D5v5ub7JFRihx9d-VOpHYOo"
        prod_sheets_id = "1pxSyLLZ-G3U3wwTYNgX_Qzijv7Mzn_6xSRIxGrM9l-4"
        default_sheets_id = prod_sheets_id if os.getenv("ENVIRONMENT") == "production" else dev_sheets_id
        self.google_sheets_id = os.getenv("GOOGLE_SHEETS_ID", default_sheets_id)
        self.company_sheet_name = "ä¼šç¤¾ä¸€è¦§"
        
        self._validate_required_vars()
    
    def _validate_required_vars(self):
        """Validate that all required environment variables are set."""
        required_vars = [
            ("GCS_BUCKET_NAME", self.gcs_bucket_name),
            ("GCP_PROJECT_ID", self.gcp_project_id),
            ("COHERE_API_KEY", self.cohere_api_key)
        ]
        
        missing_vars = [name for name, value in required_vars if not value]
        if missing_vars:
            raise RuntimeError(f"FATAL: Required environment variables are missing: {', '.join(missing_vars)}")


# Initialize configuration and clients
config = Config()
app = FastAPI(
    title="Image Search and Vectorization API",
    version="1.0.0",
    description="API for vectorizing Google Drive images and performing similarity search"
)
cohere_client = cohere.Client(config.cohere_api_key)
run_client = run_v2.JobsClient()

class VectorizeRequest(BaseModel):
    """Request model for vectorization endpoint."""
    uuid: str
    drive_url: str
    use_embed_v4: bool = False


class VectorizeTask(BaseModel):
    """Single vectorization task model."""
    uuid: str
    drive_url: str
    company_name: str = ""
    use_embed_v4: bool = False


class BatchVectorizeRequest(BaseModel):
    """Request model for batch vectorization endpoint."""
    tasks: List[VectorizeTask]


class SearchRequest(BaseModel):
    """Request model for search endpoint."""
    uuid: str
    q: Optional[str] = None
    top_k: int = 5
    trigger: str = "é¡ä¼¼ç”»åƒæ¤œç´¢"
    exclude_files: List[str] = []
    use_embed_v4: bool = False


class JobService:
    """Service for managing Cloud Run Jobs."""
    
    def __init__(self, config: Config, run_client: run_v2.JobsClient):
        self.config = config
        self.run_client = run_client
    
    def trigger_vectorization_job(self, uuid: str, drive_url: str, use_embed_v4: bool = False) -> Dict:
        """
        Trigger a Cloud Run Job for single UUID vectorization.
        
        Args:
            uuid: Company UUID
            drive_url: Google Drive folder URL
            use_embed_v4: Whether to use embed-v4.0 model
            
        Returns:
            Dict with job execution information
            
        Raises:
            Exception: If job execution fails
        """
        print(f"API: Received request to start vectorization job for UUID: {uuid}")
        
        job_parent = f"projects/{self.config.gcp_project_id}/locations/{self.config.gcp_region}"
        job_name = f"{job_parent}/jobs/{self.config.vectorize_job_name}"
        
        try:
            print(f"  -> Attempting to run job: {job_name}")
            
            request_object = run_v2.RunJobRequest(
                name=job_name,
                overrides=run_v2.RunJobRequest.Overrides(
                    container_overrides=[
                        run_v2.RunJobRequest.Overrides.ContainerOverride(
                            env=[
                                {"name": "UUID", "value": uuid},
                                {"name": "DRIVE_URL", "value": drive_url},
                                {"name": "USE_EMBED_V4", "value": str(use_embed_v4)},
                                {"name": "GCS_BUCKET_NAME", "value": self.config.gcs_bucket_name},
                                {"name": "COHERE_API_KEY", "value": self.config.cohere_api_key}
                            ]
                        )
                    ]
                )
            )
            
            response = self.run_client.run_job(request=request_object)
            
            # Extract execution info from response
            if hasattr(response, 'name'):
                execution_info = response.name
            elif hasattr(response, 'metadata'):
                execution_info = str(response.metadata)
            else:
                execution_info = f"Job triggered for {uuid}"
            
            print(f"  -> Job execution started. Info: {execution_info}")
            return {
                "message": f"Vectorization job started successfully for UUID: {uuid}",
                "execution_info": execution_info,
                "job_name": self.config.vectorize_job_name
            }
            
        except Exception as e:
            error_msg = f"Failed to start Cloud Run Job: {str(e)}"
            print(f"  -> ERROR: {error_msg}")
            traceback.print_exc()
            raise Exception(error_msg)

    def trigger_batch_vectorization_job(self, tasks: List[VectorizeTask]) -> Dict:
        """
        Trigger a Cloud Run Job for batch vectorization of multiple UUIDs.
        
        Args:
            tasks: List of vectorization tasks
            
        Returns:
            Dict with job execution information
            
        Raises:
            Exception: If job execution fails
        """
        print(f"API: Received request to start batch vectorization job for {len(tasks)} tasks")
        
        job_parent = f"projects/{self.config.gcp_project_id}/locations/{self.config.gcp_region}"
        job_name = f"{job_parent}/jobs/{self.config.vectorize_job_name}"
        
        try:
            print(f"  -> Attempting to run batch job: {job_name}")
            
            # Serialize tasks to JSON for passing as environment variable
            import json
            tasks_json = json.dumps([task.dict() for task in tasks])
            
            request_object = run_v2.RunJobRequest(
                name=job_name,
                overrides=run_v2.RunJobRequest.Overrides(
                    container_overrides=[
                        run_v2.RunJobRequest.Overrides.ContainerOverride(
                            env=[
                                {"name": "BATCH_MODE", "value": "true"},
                                {"name": "BATCH_TASKS", "value": tasks_json},
                                {"name": "GCS_BUCKET_NAME", "value": self.config.gcs_bucket_name},
                                {"name": "COHERE_API_KEY", "value": self.config.cohere_api_key}
                            ]
                        )
                    ]
                )
            )
            
            response = self.run_client.run_job(request=request_object)
            
            # Extract execution info from response
            if hasattr(response, 'name'):
                execution_info = response.name
            elif hasattr(response, 'metadata'):
                execution_info = str(response.metadata)
            else:
                execution_info = f"Batch job triggered for {len(tasks)} tasks"
            
            print(f"  -> Batch job execution started. Info: {execution_info}")
            return {
                "message": f"Batch vectorization job started successfully for {len(tasks)} tasks",
                "execution_info": execution_info,
                "job_name": self.config.vectorize_job_name,
                "task_count": len(tasks)
            }
            
        except Exception as e:
            error_msg = f"Failed to start batch Cloud Run Job: {str(e)}"
            print(f"  -> ERROR: {error_msg}")
            traceback.print_exc()
            raise Exception(error_msg)


# Initialize services
job_service = JobService(config, run_client)


@app.post("/vectorize", status_code=202)
async def trigger_vectorization_job(request: VectorizeRequest):
    """Triggers a Cloud Run Job to perform vectorization."""
    try:
        result = job_service.trigger_vectorization_job(request.uuid, request.drive_url, request.use_embed_v4)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/vectorize-batch", status_code=202)
async def trigger_batch_vectorization_job(request: BatchVectorizeRequest):
    """Triggers a Cloud Run Job to perform batch vectorization."""
    try:
        result = job_service.trigger_batch_vectorization_job(request.tasks)
        return result
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


class SearchService:
    """Service for managing image search operations."""
    
    def __init__(self, config: Config, cohere_client: cohere.Client):
        self.config = config
        self.cohere_client = cohere_client
    
    def search_similar_images(self, uuid: str, query: str, top_k: int, exclude_files: List[str] = None, use_embed_v4: bool = False) -> Dict:
        """
        Search for similar images using text query.
        
        Args:
            uuid: Company UUID
            query: Search query text
            top_k: Number of results to return
            exclude_files: List of filenames to exclude from search results
            use_embed_v4: Whether to use embed-v4.0 model
            
        Returns:
            Dict with search results
        """
        print(f"ğŸ§  Generating embedding for query: '{query}'")
        if exclude_files:
            print(f"ğŸ“‹ Excluding {len(exclude_files)} files from search")
        
        try:
            searcher = ImageSearcher(uuid=uuid, bucket_name=self.config.gcs_bucket_name)
        except FileNotFoundError as e:
            print(f"âŒ Vector data not found: {e}")
            raise HTTPException(status_code=404, detail=f"Vector data for UUID '{uuid}' not found.")
        
        embed_model = "embed-v4.0" if use_embed_v4 else "embed-multilingual-v3.0"
        print(f"ğŸ”§ Using embedding model: {embed_model}")
        
        response = self.cohere_client.embed(
            texts=[query], 
            model=embed_model,
            input_type="search_query"
        )
        query_embedding = response.embeddings[0]
        
        results = searcher.search_images(query_embedding=query_embedding, top_k=top_k, exclude_files=exclude_files)
        print(f"âœ… Similarity search completed. Returning {len(results)} results")
        
        return {"query": query, "results": results}
    
    def search_random_images(self, uuid: str, count: int, exclude_files: List[str] = None) -> Dict:
        """
        Search for random images.
        
        Args:
            uuid: Company UUID
            count: Number of random images to return
            exclude_files: List of filenames to exclude from search results
            
        Returns:
            Dict with search results
        """
        if exclude_files:
            print(f"ğŸ“‹ Excluding {len(exclude_files)} files from random search")
            
        try:
            searcher = ImageSearcher(uuid=uuid, bucket_name=self.config.gcs_bucket_name)
        except FileNotFoundError as e:
            print(f"âŒ Vector data not found: {e}")
            raise HTTPException(status_code=404, detail=f"Vector data for UUID '{uuid}' not found.")
        
        results = searcher.random_image_search(count=count, exclude_files=exclude_files)
        print(f"âœ… Random search completed. Returning {len(results)} results")
        
        return {"query": "ãƒ©ãƒ³ãƒ€ãƒ æ¤œç´¢", "results": results}


# Initialize services
search_service = SearchService(config, cohere_client)


class SheetsService:
    """Service for managing Google Sheets operations."""
    
    def __init__(self, config: Config):
        self.config = config
        self._gc = self._get_sheets_client()
    
    def _get_sheets_client(self) -> gspread.Client:
        """Initialize Google Sheets client with appropriate credentials."""
        environment = os.getenv("ENVIRONMENT", "local")
        
        if environment == "production":
            import google.auth
            credentials, _ = google.auth.default(scopes=[
                'https://www.googleapis.com/auth/spreadsheets.readonly',
                'https://www.googleapis.com/auth/drive.readonly'
            ])
            return gspread.authorize(credentials)
        else:
            key_file = "config/marketing-automation-461305-2acf4965e0b0.json"
            if os.path.exists(key_file):
                credentials = service_account.Credentials.from_service_account_file(
                    key_file,
                    scopes=[
                        'https://www.googleapis.com/auth/spreadsheets.readonly',
                        'https://www.googleapis.com/auth/drive.readonly'
                    ]
                )
                return gspread.authorize(credentials)
            else:
                import google.auth
                credentials, _ = google.auth.default(scopes=[
                    'https://www.googleapis.com/auth/spreadsheets.readonly',
                    'https://www.googleapis.com/auth/drive.readonly'
                ])
                return gspread.authorize(credentials)
    
    def get_companies_for_auto_update(self) -> List[Dict]:
        """
        Fetch companies that have both URL and checkbox=TRUE from Google Sheets.
        
        Returns:
            List of dictionaries with company information
        """
        try:
            spreadsheet = self._gc.open_by_key(self.config.google_sheets_id)
            sheet = spreadsheet.worksheet(self.config.company_sheet_name)
            
            # Get all values from the sheet
            all_values = sheet.get_all_values()
            
            if len(all_values) < 2:  # No data rows
                print("No data found in the company sheet")
                return []
            
            data_rows = all_values[1:]
            
            companies_to_update = []
            
            for row_index, row in enumerate(data_rows, start=2):  # Start from row 2 (skip header)
                try:
                    # Assuming columns: A=UUID, B=Company Name, C=Drive URL, F=Checkbox
                    if len(row) < 6:
                        continue
                    
                    uuid = row[0].strip() if len(row) > 0 else ""
                    company_name = row[1].strip() if len(row) > 1 else ""
                    drive_url = row[2].strip() if len(row) > 2 else ""
                    checkbox_status = row[5].strip().upper() if len(row) > 5 else ""
                    
                    # Check if URL exists and checkbox is TRUE
                    if drive_url and checkbox_status == "TRUE":
                        companies_to_update.append({
                            "uuid": uuid,
                            "company_name": company_name,
                            "drive_url": drive_url,
                            "row_number": row_index,
                            "use_embed_v4": "embed-v4.0" in company_name
                        })
                        print(f"Found company for auto-update: {company_name} (UUID: {uuid})")
                
                except Exception as e:
                    print(f"Error processing row {row_index}: {e}")
                    continue
            
            print(f"Total companies found for auto-update: {len(companies_to_update)}")
            return companies_to_update
            
        except Exception as e:
            print(f"Error fetching companies from Google Sheets: {e}")
            traceback.print_exc()
            raise HTTPException(status_code=500, detail=f"Failed to fetch companies from Google Sheets: {str(e)}")


# Initialize sheets service
sheets_service = SheetsService(config)


@app.post("/auto-update")
async def auto_update_vectors():
    """
    Endpoint for automatic vector file updates.
    Fetches companies with checkbox=TRUE from Google Sheets and triggers vectorization.
    """
    try:
        print("ğŸ”„ Starting automatic vector update process...")
        
        # Get companies that need to be updated
        companies = sheets_service.get_companies_for_auto_update()
        
        if not companies:
            return {
                "message": "No companies found with enabled auto-update",
                "processed_count": 0,
                "results": []
            }
        
        results = []
        success_count = 0
        failure_count = 0
        
        # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®Ÿè¡Œ
        try:
            print(f"ğŸ¯ Triggering batch vectorization for {len(companies)} companies")
            
            # ã‚¿ã‚¹ã‚¯ãƒªã‚¹ãƒˆã‚’ä½œæˆ
            tasks = []
            for company in companies:
                task = VectorizeTask(
                    uuid=company['uuid'],
                    drive_url=company['drive_url'],
                    company_name=company['company_name'],
                    use_embed_v4=company['use_embed_v4']
                )
                tasks.append(task)
            
            # ãƒãƒƒãƒã‚¸ãƒ§ãƒ–ã‚’å®Ÿè¡Œ
            batch_result = job_service.trigger_batch_vectorization_job(tasks)
            
            results.append({
                "status": "success",
                "message": batch_result['message'],
                "task_count": batch_result.get('task_count', len(companies)),
                "execution_info": batch_result.get('execution_info', '')
            })
            success_count = len(companies)
            
        except Exception as e:
            error_msg = f"Failed to trigger batch vectorization: {str(e)}"
            print(f"âŒ {error_msg}")
            
            results.append({
                "status": "error",
                "message": error_msg
            })
            failure_count = len(companies)
        
        print(f"âœ… Auto-update process completed. Success: {success_count}, Failures: {failure_count}")
        
        return {
            "message": f"Auto-update process completed. {success_count} successful, {failure_count} failed.",
            "processed_count": len(companies),
            "success_count": success_count,
            "failure_count": failure_count,
            "results": results
        }
        
    except Exception as e:
        print(f"âŒ Error in auto-update process: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"Auto-update process failed: {str(e)}")


@app.get("/search", response_model=Dict)
def search_images_api(
    uuid: str = Query(..., description="UUID of the company to search for"),
    q: Optional[str] = Query(None, description="Search query text"),
    top_k: int = Query(5, ge=1, le=50, description="Number of results to return"),
    trigger: str = Query("é¡ä¼¼ç”»åƒæ¤œç´¢", description="Search type: 'é¡ä¼¼ç”»åƒæ¤œç´¢' or 'ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒæ¤œç´¢'"),
):
    """Performs image search using the specified vector data."""
    print(f"ğŸ” Search API called: UUID={uuid}, trigger={trigger}, top_k={top_k}")
    if q:
        print(f"   Query: '{q}'")
    
    try:
        if trigger == "é¡ä¼¼ç”»åƒæ¤œç´¢":
            if not q:
                print("âŒ Missing query parameter for similarity search")
                raise HTTPException(status_code=400, detail="Query 'q' is required for similar image search.")
            
            return search_service.search_similar_images(uuid, q, top_k)
            
        elif trigger == "ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒæ¤œç´¢":
            return search_service.search_random_images(uuid, top_k)
            
        else:
            print(f"âŒ Invalid trigger: {trigger}")
            raise HTTPException(status_code=400, detail=f"Invalid trigger: {trigger}")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Unexpected error during search: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred during search: {str(e)}")


@app.post("/search", response_model=List[Dict])
def search_images_post(request: SearchRequest):
    """
    Performs image search using the specified vector data (POST version).
    Returns results as a list (compatible with api_caller.gs).
    """
    print(f"ğŸ” Search API (POST) called: UUID={request.uuid}, trigger={request.trigger}, top_k={request.top_k}")
    if request.q:
        print(f"   Query: '{request.q}'")
    if request.exclude_files:
        print(f"   Excluding {len(request.exclude_files)} files")
    
    try:
        if request.trigger == "é¡ä¼¼ç”»åƒæ¤œç´¢":
            if not request.q:
                print("âŒ Missing query parameter for similarity search")
                raise HTTPException(status_code=400, detail="Query 'q' is required for similar image search.")
            
            result = search_service.search_similar_images(
                request.uuid, 
                request.q, 
                request.top_k,
                request.exclude_files,
                request.use_embed_v4
            )
            return result.get("results", [])
            
        elif request.trigger == "ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒæ¤œç´¢":
            result = search_service.search_random_images(
                request.uuid, 
                request.top_k,
                request.exclude_files
            )
            return result.get("results", [])
            
        else:
            print(f"âŒ Invalid trigger: {request.trigger}")
            raise HTTPException(status_code=400, detail=f"Invalid trigger: {request.trigger}")
            
    except HTTPException:
        raise
    except Exception as e:
        print(f"âŒ Unexpected error during search: {e}")
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"An unexpected error occurred during search: {str(e)}")


@app.get("/")
def health_check():
    """Health check endpoint."""
    return {"status": "ok", "service": "image-search-api", "version": "1.0.0"}
