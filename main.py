import os
import time
import json
import traceback
from typing import List, Optional, Dict

import cohere
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException, Query, BackgroundTasks, Body
from pydantic import BaseModel
from google.cloud import pubsub_v1, storage

# æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ã¨Driveã‚¹ã‚­ãƒ£ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from search import ImageSearcher
from drive_scanner import list_files_in_drive_folder

load_dotenv()

# --- è¨­å®š ---
app = FastAPI(
    title="ç”»åƒæ¤œç´¢ãƒ»ãƒ™ã‚¯ãƒˆãƒ«åŒ–API (Pub/Subå¯¾å¿œç‰ˆ)",
    version="3.0.0"
)
GCS_BUCKET_NAME = os.getenv("GCS_BUCKET_NAME")
GCP_PROJECT_ID = os.getenv("GCP_PROJECT_ID")
PUBSUB_TOPIC_ID = "vectorize-tasks" 

# --- ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ ---
co = cohere.Client(os.getenv("COHERE_API_KEY"))
storage_client = storage.Client()
publisher = pubsub_v1.PublisherClient()
topic_path = publisher.topic_path(GCP_PROJECT_ID, PUBSUB_TOPIC_ID)

# --- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
searcher_cache: Dict[str, tuple[float, ImageSearcher]] = {}
CACHE_TTL_SECONDS = 300

def get_searcher_for_uuid(uuid: str) -> ImageSearcher:
    # ... (ã“ã®é–¢æ•°ã¯å¤‰æ›´ãªã—) ...
    current_time = time.time()
    if uuid in searcher_cache and (current_time - searcher_cache[uuid][0]) < CACHE_TTL_SECONDS:
        print(f"ğŸ“¦ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰ '{uuid}' ã®æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’è¿”ã—ã¾ã™ã€‚")
        return searcher_cache[uuid][1]
    print(f"âœ¨ '{uuid}' ã®æ¤œç´¢ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
    try:
        searcher = ImageSearcher(
            uuid=uuid,
            embeddings_dir='vector_data',
            bucket_name=GCS_BUCKET_NAME
        )
        searcher_cache[uuid] = (current_time, searcher)
        return searcher
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail=f"UUID '{uuid}' ã«å¯¾å¿œã™ã‚‹ãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

# --- APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ ---

class VectorizeRequest(BaseModel):
    uuid: str
    drive_url: str

@app.post("/vectorize", status_code=202)
async def vectorize_commander(request: VectorizeRequest):
    """å¸ä»¤å¡”: Driveã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã€ãƒ•ã‚¡ã‚¤ãƒ«æ¯ã®å‡¦ç†ã‚¿ã‚¹ã‚¯ã‚’Pub/Subã«ç™ºè¡Œ"""
    print(f"å¸ä»¤å¡”: UUID '{request.uuid}' ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¿ã‚¹ã‚¯ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    try:
        files_to_process = list_files_in_drive_folder(request.drive_url)
        if not files_to_process:
            return {"message": "å¯¾è±¡ãƒ•ã‚©ãƒ«ãƒ€ã«ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"}

        print(f"  -> {len(files_to_process)} ä»¶ã®ç”»åƒã‚’æ¤œå‡ºã€‚Pub/Subã«ã‚¿ã‚¹ã‚¯ã‚’ç™ºè¡Œã—ã¾ã™...")
        
        published_count = 0
        for file_info in files_to_process:
            message_payload = {
                "uuid": request.uuid,
                "file_id": file_info['id'],
                "file_name": file_info['name'],
                "web_view_link": file_info['webViewLink'],
                "folder_path": file_info['folder_path']
            }
            message_data = json.dumps(message_payload).encode("utf-8")
            future = publisher.publish(topic_path, message_data)
            future.result() # é€ä¿¡å®Œäº†ã‚’å¾…ã¤
            published_count += 1

        # æ—¢å­˜ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
        if request.uuid in searcher_cache:
            del searcher_cache[request.uuid]
            print(f"ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ: {request.uuid}")
            
        return {"message": f"{published_count} ä»¶ã®ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¿ã‚¹ã‚¯ã‚’Pub/Subã«ç™ºè¡Œã—ã¾ã—ãŸã€‚"}

    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"ã‚¿ã‚¹ã‚¯ç™ºè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

class AggregateRequest(BaseModel):
    uuid: str

@app.post("/aggregate", status_code=200)
async def aggregate_results(request: AggregateRequest):
    """çµ±åˆå½¹: GCSä¸Šã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ã—ã¦æœ€çµ‚çš„ãªJSONã‚’ä½œæˆ"""
    uuid = request.uuid
    print(f"çµ±åˆå½¹: UUID '{uuid}' ã®çµæœçµ±åˆå‡¦ç†ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
    
    bucket = storage_client.bucket(GCS_BUCKET_NAME)
    temp_prefix = f"temp/{uuid}/"
    
    blobs = list(bucket.list_blobs(prefix=temp_prefix))
    if not blobs:
        raise HTTPException(status_code=404, detail=f"UUID '{uuid}' ã®å‡¦ç†çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
    
    print(f"  -> {len(blobs)} ä»¶ã®ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡ºã€‚çµ±åˆã—ã¾ã™...")
    
    all_embeddings = []
    for blob in blobs:
        try:
            data = json.loads(blob.download_as_string())
            all_embeddings.append(data)
        except Exception as e:
            print(f"  âš ï¸ ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ« {blob.name} ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—: {e}")

    # æœ€çµ‚çš„ãªJSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    final_blob = bucket.blob(f"{uuid}.json")
    final_blob.upload_from_string(
        json.dumps(all_embeddings, ensure_ascii=False, indent=2),
        content_type="application/json"
    )
    print(f"  âœ… æœ€çµ‚ãƒ•ã‚¡ã‚¤ãƒ« '{final_blob.name}' ã‚’ä¿å­˜ã—ã¾ã—ãŸã€‚")
    
    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
    for blob in blobs:
        blob.delete()
    print(f"  ğŸ—‘ï¸  ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã™ã¹ã¦å‰Šé™¤ã—ã¾ã—ãŸã€‚")
    
    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
    if uuid in searcher_cache:
        del searcher_cache[uuid]
        print(f"ğŸ§¹ ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ: {uuid}")

    return {"message": f"{len(all_embeddings)}ä»¶ã®çµæœã‚’ '{uuid}.json' ã«çµ±åˆã—ã¾ã—ãŸã€‚"}


# æ¤œç´¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯å¤‰æ›´ãªã—
@app.get("/search", response_model=Dict)
def search_images_api(
    uuid: str = Query(..., description="æ¤œç´¢å¯¾è±¡ä¼æ¥­ã®UUID"),
    q: Optional[str] = Query(None, description="æ¤œç´¢ã‚¯ã‚¨ãƒª"),
    top_k: int = Query(5, ge=1, le=50),
    trigger: str = Query("é¡ä¼¼ç”»åƒæ¤œç´¢"),
):
    print(f"ğŸ” æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡ - uuid: '{uuid}', trigger: '{trigger}', q: '{q}'")
    searcher = get_searcher_for_uuid(uuid)
    try:
        if trigger == "é¡ä¼¼ç”»åƒæ¤œç´¢":
            if not q:
                raise HTTPException(status_code=400, detail="é¡ä¼¼ç”»åƒæ¤œç´¢ã«ã¯æ¤œç´¢ã‚¯ã‚¨ãƒª 'q' ãŒå¿…é ˆã§ã™ã€‚")
            response = co.embed(texts=[q], model="embed-multilingual-v3.0", input_type="search_query")
            query_embedding = response.embeddings[0]
            results = searcher.search_images(query_embedding=query_embedding, top_k=top_k)
            return {"query": q, "results": results}
        elif trigger == "ãƒ©ãƒ³ãƒ€ãƒ ç”»åƒæ¤œç´¢":
            results = searcher.random_image_search(count=top_k)
            return {"query": "ãƒ©ãƒ³ãƒ€ãƒ æ¤œç´¢", "results": results}
        else:
            raise HTTPException(status_code=400, detail=f"ç„¡åŠ¹ãªãƒˆãƒªã‚¬ãƒ¼: {trigger}")
    except Exception as e:
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=f"æ¤œç´¢ä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")


